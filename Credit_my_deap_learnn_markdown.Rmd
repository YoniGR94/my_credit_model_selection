---
title: "Different Techniches to Analyze Credit Balance"
output: github_document
always_allow_html: true
---

how good can we predict Credit balance?

In order to race our models, we will use the Credit data from ILSR package.

About this data:

"A simulated data set containing information on ten thousand customers. The aim here is to predict which customers will default on their credit card debt."* 

*[RDocumentation](https://www.rdocumentation.org/packages/ISLR/versions/1.2/topics/Credit)


#  set Data

first, let's set the Environment

```{r library, error=FALSE, message=FALSE, warning=FALSE}
#collect data:
library(ISLR)
attach(Credit)

#neural network
library(tensorflow)
#install_tensorflow()
library(keras)
#install_keras()
#install_minicomda

#data tools:
library(dplyr)
library(tidyr)
library(Matrix)

#visual
library(ggplot2)
library(hrbrthemes)
library(viridis)
library(knitr)
library(kableExtra)
library(scales)
library(jtools)

#random Forest
library(randomForest)

#other models
library(glmnet)
```

now we will see the data's structure

```{r see data, warning=FALSE, message=FALSE}
head(Credit[,-1],6) %>%
  kbl() %>%
  kable_material(c("striped", "hover"))
```


```{r, error=FALSE, message=FALSE, warning=FALSE}
Credit %>%
  ggplot(aes(x=Balance))+
  geom_histogram(color= alpha("black", 0.7),fill= "green" )+
  geom_vline(xintercept= mean(Balance), color= "blue",lty= "dashed")+
  theme_linedraw()+labs( x= "Balance in $10,000")
```
As we can see, $Balance$ is not normal, due to a dense $0$ value

```{r, error=FALSE, message=FALSE, warning=FALSE}
Credit %>%
  ggplot(aes(y=Balance, x=Age, ))+
  geom_point(y=Balance, x=Age, size= 0.7)+#,fill= Ethnicity)
  geom_smooth(method = "glm")+ylim(min(Balance), max(Balance))

Credit %>%
  ggplot(aes(y=Balance, x=Ethnicity,fill= Ethnicity))+
  geom_boxplot(size= 0.7)+labs(x = "")

```

we will ad some variables

```{r mutate, error=FALSE, message=FALSE, warning=FALSE}
#set data to Train & Test
Credit <- na.omit(Credit)
n <- nrow(Credit)
set.seed (13)
ntest <- trunc(n / 3)
testid <- sample (1:n, ntest)

#manipulate data:
Credit<- Credit %>%
  #mutate(Married= (ifelse(Married== "Yes" ,T,F)))%>%
  mutate(High_deg= Education>=13)%>%
  mutate(Age_2= Age^2)%>%
  mutate(Bride= (Gender== 'Female')&(Married== 'Yes'))%>%
  select(-ID)
```

# Models

# Linear

#   LM

assumption

$(Y|X) \sim N(BX,\epsilon)$

```{r LM, warning= F}
lmfit <- lm(Balance ~ ., data = Credit[-testid , ])
lmpred <- predict(lmfit , Credit[testid , ])
err_lm<- (abs(Credit$Balance[testid] - lmpred))
mean(abs(err_lm))

#summary(lmfit)
export_summs(lmfit)

```

#   lasso

*(use vectors)

assumption

$(Y|X) \sim N(BX,\epsilon)$, like LM.

but this time we use shrinkage method in order to reduce variance & over fitting. so our minimizing function define as

$RSS+ \lambda {\Si3gma}_{j=1}^p |\beta_j|$

when $p=length( \beta)$ and $\lambda$ is a hyper parameter.

```{r Lasso}
x <- scale(model.matrix(Balance ~ . - 1, data = Credit))
y <- Credit$Balance

#glmnet
cvfit <- cv.glmnet(x[-testid , ], y[-testid],
                     type.measure = "mae")
cpred <- predict(cvfit , x[testid , ], s = "lambda.min")
err_cp<- abs(y[testid] - cpred)
mean(abs(err_cp))


```

#  Trees

The main algorithm in randomforest, adaboost, etc is splitting the data each time into two samples, in the most effective way by reevaluating the error function.
This is a very weak learner, but it can be used to create deeper learning.

#   Random Forest

A mean of n-tree
```{r randomForest}
rf_s<- randomForest(formula= Balance ~ ., data = Credit[-testid , ],
                    ntree= 1500, mtry= 6, na.action = na.omit )

pred_s<- predict(rf_s,newdata = Credit[-testid , ] )
rf_pred <- predict(rf_s , Credit[testid , ], s = "lambda.min")
err_rf<- y[testid] - rf_pred
mean(abs(err_rf))
```

#   Adaboost

A mean of n-tree with weights
```{r adaboost}
norm_y<- 2*y/(max(y)+min(y))-1

adb_s<-randomForest(formula= Balance ~ ., data = Credit[-testid , ],
                    ntree= 1500, mtry= 14, na.action = na.omit, importance= T )

pred_abs <- predict(adb_s , Credit[testid , ], s = "lambda.min")
pred_abs<- head(as.vector(pred_abs),133)
err_adb<- y[testid] - pred_abs
mean(abs(err_adb))
```

#  Neural Network

Creating of network of nonlinear function and weights, that evaluate the prediction.

this method is the hardest to present due to the coplexativity of the net.

#   set seed

we set our net using 50 nodes of relu, dropout and 20 nodes of relu.

```{r keras set, warning=FALSE}
modnn <- keras_model_sequential () %>%
  layer_dense(units = 50, activation = "relu",
              input_shape = ncol(x)) %>%
  layer_dropout(rate = 0.4) %>%
  layer_dense(units = 20, activation = 'relu') %>%
  #layer_dropout(rate = 0.3) %>%
  layer_dense(units = 1)

modnn %>% compile(loss = "mse",
                  optimizer = optimizer_rmsprop (),
                  metrics = list("mean_absolute_error")
                  )
modnn
```


Using the net:

```{r apply Keras, echo=TRUE, results='hide'}
mod_Credit <- modnn %>% fit(
  x[-testid , ], y[-testid], epochs = 1500, batch_size = 32,
  validation_data = list(x[testid , ], y[testid ])
)
```

Keras result

```{r Keras result}
#show Keras result
summary(mod_Credit)

plot(mod_Credit)+theme_gray()+
  theme(plot.caption = element_text(size = 6,hjust= 0),
        legend.position = c(.95, .95),
    legend.justification = c("right", "top"),
    legend.box.just = "right")#,
    #legend.margin = margin(6, 6, 6, 6))

nnpred <- predict(modnn , x[testid , ])
err_nn<- y[testid] - nnpred
mean(abs(err_nn))
```


# sum result

we used the same seed to test all methods, so now we can compare the error of each data
```{r sum pred, echo=TRUE}
#data of all prediction
my_pred<- data.frame(c(lmpred,cpred,rf_pred,pred_abs,nnpred))
m<- length(testid)
modl_nam<-c("Linear", "Lasso", "Random_forrest","Adaboost","Neural_network")
my_pred$Model<- c(rep(modl_nam[1],m),rep(modl_nam[2],m),
                   rep(modl_nam[3],m),rep(modl_nam[4],m),rep(modl_nam[5],m) )
my_pred$Balance<-rep(y[testid],5)
colnames(my_pred)[1]<- "Predict"

all_sd<- c(err_lm,err_cp,err_rf,err_adb,err_nn)
#caption
order_script<- order(modl_nam)
script<- paste("sd of models: ",modl_nam[order_script[1]], "is", round(all_sd[order_script[1]],3))
for (i in order_script[-1]) {
  script<- paste(script, ", ", modl_nam[i], "is", round(all_sd[i],3) )}

my_pred %>%
  ggplot( aes(x= Model ,y=Balance-Predict, fill= Model)) +
  geom_violin()+
  scale_fill_viridis(discrete = TRUE, alpha=0.6) +
  geom_jitter(color="black", size=0.45) +
  theme_dark() +
  theme(
    legend.position="none",
    plot.title = element_text(size=12,hjust = 0.5,face = "bold"),
    plot.caption = element_text(size = 8,hjust= 0),
    axis.title = element_text(size = 8))+ ylab("Error")+
  labs(title = "Error Violin",caption = script)
```

```{r sum error, eval=FALSE, include=FALSE}
my_error<- data.frame(c(err_lm,err_cp,err_rf,err_adb,err_nn))
m<- length(testid)
modl_nam<-c("Linear", "Lasso", "Random_forrest","Adaboost","Neural_network")
my_error$Model<- c(rep(modl_nam[1],m),rep(modl_nam[2],m),
                   rep(modl_nam[3],m),rep(modl_nam[4],m),rep(modl_nam[5],m) )
my_error$Balance<-rep(y[testid],5)
colnames(my_error)[1]<- "Predict"

my_error %>%
  ggplot( aes(x= Model ,y=Balance, fill= Model)) +
  #geom_violin()+
  geom_boxplot()+
  
  scale_fill_viridis(discrete = TRUE, alpha=0.6) +
  geom_jitter(color="black", size=0.4) +
  theme_dark() +
  theme(
    legend.position="right",
    plot.title = element_text(size=11),
    axis.title = element_text(size = 8),
    plot.caption = element_text(size = 6)
  ) + labs(caption = script, title = "Error Violin") +
  xlab("")+ ylab("Error")
```

